{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation von Spam Mails und E-Maildaten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in diesem Dokument wird für GPT3.5 tests eine Azure API benötigt, hierzu sollte die Sectrets.toml folgendermaßen aussehen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[API_TOKEN]\n",
    "\n",
    "openai_azure = \"eigener key\"\n",
    "OPENAI_API_VERSION = \"2023-05-15\"\n",
    "OPENAI_API_ENGINE = \"name Engine\"\n",
    "OPENAI_API_BASE = \"https://spie.openai.azure.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "import replicate\n",
    "import os\n",
    "import tiktoken\n",
    "import toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens und Kosten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kostenrechner(anzahl_input,anzahl_output):\n",
    "    if llm == 'gpt-4':\n",
    "        kosten = ((0.03/1000)*anzahl_input)+((0.06/1000)*anzahl_output)\n",
    "    elif llm == 'gpt-3.5-turbo':\n",
    "        kosten = ((0.0015/1000)*anzahl_input)+((0.002/1000)*anzahl_output)\n",
    "    elif llm == 'replicate/llama70b-v2-chat:e951f18578850b652510200860fc4ea62b3b16fac280f83ff32282f87bbd2e48':        \n",
    "        kosten = elapsed_time_ges*(0.001400)\n",
    "    return kosten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm='gpt-4' #gpt-3.5-turbo, gpt-4, replicate/llama70b-v2-chat:e951f18578850b652510200860fc4ea62b3b16fac280f83ff32282f87bbd2e48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie die .toml-Datei\n",
    "data = toml.load(\"../.streamlit/secrets.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Werte auslesen\n",
    "if llm!=\"gpt-3.5-turbo\":\n",
    "    replicate_api_token = data[\"API_TOKEN\"][\"replicate_api_token\"]\n",
    "    os.environ['REPLICATE_API_TOKEN'] = replicate_api_token\n",
    "    openai_api = data[\"API_TOKEN\"][\"openai_api\"]\n",
    "    openai.api_key = openai_api\n",
    "else:\n",
    "    openai.api_type = \"azure\"  \n",
    "    openai.api_key = data[\"API_TOKEN\"][\"openai_azure\"]\n",
    "    openai.api_base = data[\"API_TOKEN\"][\"OPENAI_API_BASE\"]\n",
    "    openai.api_version = data[\"API_TOKEN\"][\"version\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### promt generierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt_response(prompt_input):\n",
    "    messages=[{f\"role\": \"system\", \"content\": context}]\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_input})\n",
    "    if llm == \"gpt-3.5-turbo\":\n",
    "        response = openai.ChatCompletion.create(messages=messages, engine=data[\"API_TOKEN\"][\"OPENAI_API_ENGINE\"])\n",
    "        full_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    elif llm == 'gpt-4':\n",
    "        response = openai.ChatCompletion.create(model=llm, messages=messages)\n",
    "        full_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        response = replicate.run(llm, \n",
    "                           input={\"prompt\": \"You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'. \"+ context + prompt_input +\" Assistant: \",\n",
    "                                  \"temperature\":0.1, \"top_p\":0.9, \"max_length\":4097, \"repetition_penalty\":1})\n",
    "        full_response = ''\n",
    "        for item in response:\n",
    "            full_response += item\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(df,  anzahl, cat_label):\n",
    "    # Liste zum Speichern der ausgewählten DataFrames\n",
    "    dfs = []\n",
    "    # Gruppieren nach 'Kategorie' und nehmen von 5 Stichproben für jede Gruppe\n",
    "    for name, group in df.groupby(cat_label):\n",
    "        dfs.append(group.sample(min(len(group), anzahl)))\n",
    "\n",
    "    # Kombinieren aller gesammelten DataFrames\n",
    "    con_df = pd.concat(dfs)\n",
    "    \n",
    "    return con_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"I will send you titles of newspaper articles in English now, which you should classify. The categories are: [BUSINESS, ENTERTAINMENT, HEALTH, NATION, SCIENCE, SPORTS, TECHNOLOGY, WORLD]. Always respond with the respective category. Your answer should only be one word. \\n The Title starts here:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/labelled_newscatcher_dataset.csv', delimiter=';')\n",
    "df = df.iloc[:, [0, 4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = subset(df,20, \"topic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"subset_df.to_csv('../Data/subset_news_20.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = pd.read_csv('../Data/subset_news_20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"subset_df = subset_df.iloc[70:90]#subset_df.iloc[:30],  subset_df.iloc[30:60],  subset_df.iloc[60:90], subset_df.iloc[90:120], subset_df.iloc[120:150],  subset_df.iloc[150:180], subset_df.iloc[180:210],  subset_df.iloc[210:240]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "Ges = len(subset_df)\n",
    "ges_len_input = 0\n",
    "ges_len_responce = 0\n",
    "elapsed_time_ges = 0\n",
    "count=0\n",
    "# Iterieren über die \"Text\"-Spalte und Drucken jedes Eintrags\n",
    "for index,text_entry in enumerate(subset_df['title']):\n",
    "    cat = subset_df[\"topic\"].iloc[index]\n",
    "    if 'gpt'in llm:\n",
    "        len_input = num_tokens_from_string(text_entry, llm)\n",
    "        ges_len_input += len_input\n",
    "    else:\n",
    "        ges_len_responce = 0\n",
    "    #ausführung Modell + Zeitstoppen\n",
    "    start_time = time.time()\n",
    "    responce = generate_gpt_response(text_entry)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_ges += elapsed_time\n",
    "    if 'gpt'in llm:\n",
    "        len_output_tokens = num_tokens_from_string(responce, llm)\n",
    "        ges_len_responce += len_output_tokens\n",
    "    else:\n",
    "        ges_len_responce = 0\n",
    "    count+=1\n",
    "    kosten = kostenrechner(ges_len_input, ges_len_responce)\n",
    "    if cat == responce:\n",
    "        TP+=1\n",
    "    Acc = TP/Ges\n",
    "    print(f\"Class = {cat}, Responce = {responce}, Text = {text_entry}, time: {elapsed_time_ges} cost: {kosten} TP:{TP}\")\n",
    "    \n",
    "Acc = TP/Ges\n",
    "kosten = kostenrechner(ges_len_input, ges_len_responce)\n",
    "print(f\"The accuracy of the model is: {Acc} and cost: {kosten} and execution time: {elapsed_time_ges}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "27/30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "context=\"Please identify the content that follows the word 'Subject' as either harmless or spam. Reply with 'ham' for harmless and 'spam' for spam. Your answer should only be one word.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_spam = pd.read_csv(\\'../Data/spam_ham_dataset.csv\\', sep = \",\")\\n\\ndf_spam=df_spam[[\"label\",\"text\"]]\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_spam = pd.read_csv('../Data/spam_ham_dataset.csv', sep = \",\")\n",
    "\n",
    "df_spam=df_spam[[\"label\",\"text\"]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_spam_subset = subset(df_spam, 30,\"label\")'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_spam_subset = subset(df_spam, 30,\"label\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_spam_subset.to_csv('../Data/subset_spam_30.csv', index=False)\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_spam_subset.to_csv('../Data/subset_spam_30.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam_subset = pd.read_csv('../Data/subset_spam_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class = ham, Responce = ham, Kosten = 0.00216, TP= 1\n",
      "Class = ham, Responce = ham, Kosten = 0.008579999999999999, TP= 2\n",
      "Class = ham, Responce = ham, Kosten = 0.027419999999999996, TP= 3\n",
      "Class = ham, Responce = ham, Kosten = 0.038729999999999994, TP= 4\n",
      "Class = ham, Responce = ham, Kosten = 0.046079999999999996, TP= 5\n",
      "Class = ham, Responce = ham, Kosten = 0.049859999999999995, TP= 6\n",
      "Class = ham, Responce = ham, Kosten = 0.050699999999999995, TP= 7\n",
      "Class = ham, Responce = ham, Kosten = 0.05151, TP= 8\n",
      "Class = ham, Responce = ham, Kosten = 0.05639999999999999, TP= 9\n",
      "Class = ham, Responce = ham, Kosten = 0.05697, TP= 10\n",
      "Class = ham, Responce = ham, Kosten = 0.05927999999999999, TP= 11\n",
      "Class = ham, Responce = ham, Kosten = 0.07214999999999999, TP= 12\n",
      "Class = ham, Responce = ham, Kosten = 0.07644, TP= 13\n",
      "Class = ham, Responce = ham, Kosten = 0.09317999999999999, TP= 14\n",
      "Class = ham, Responce = ham, Kosten = 0.09449999999999999, TP= 15\n",
      "Class = ham, Responce = ham, Kosten = 0.11006999999999999, TP= 16\n",
      "Class = ham, Responce = ham, Kosten = 0.12197999999999998, TP= 17\n",
      "Class = ham, Responce = ham, Kosten = 0.13182, TP= 18\n",
      "Class = ham, Responce = ham, Kosten = 0.14534999999999998, TP= 19\n",
      "Class = ham, Responce = ham, Kosten = 0.17844, TP= 20\n",
      "Class = ham, Responce = ham, Kosten = 0.18356999999999998, TP= 21\n",
      "Class = ham, Responce = ham, Kosten = 0.18467999999999998, TP= 22\n",
      "Class = ham, Responce = ham, Kosten = 0.18629999999999997, TP= 23\n",
      "Class = ham, Responce = ham, Kosten = 0.19943999999999998, TP= 24\n",
      "Class = ham, Responce = ham, Kosten = 0.20223, TP= 25\n",
      "Class = ham, Responce = ham, Kosten = 0.20337, TP= 26\n",
      "Class = ham, Responce = ham, Kosten = 0.21222, TP= 27\n",
      "Class = ham, Responce = ham, Kosten = 0.26148, TP= 28\n",
      "Class = ham, Responce = ham, Kosten = 0.26600999999999997, TP= 29\n",
      "Class = ham, Responce = ham, Kosten = 0.26721, TP= 30\n",
      "Class = spam, Responce = spam, Kosten = 0.2709599999999999, TP= 31\n",
      "Class = spam, Responce = spam, Kosten = 0.27482999999999996, TP= 32\n",
      "Class = spam, Responce = spam, Kosten = 0.27984, TP= 33\n",
      "Class = spam, Responce = spam, Kosten = 0.28278, TP= 34\n",
      "Class = spam, Responce = spam, Kosten = 0.28841999999999995, TP= 35\n",
      "Class = spam, Responce = ham, Kosten = 0.28958999999999996, TP= 35\n",
      "Class = spam, Responce = spam, Kosten = 0.29108999999999996, TP= 36\n",
      "Class = spam, Responce = spam, Kosten = 0.29262, TP= 37\n",
      "Class = spam, Responce = spam, Kosten = 0.2991, TP= 38\n",
      "Class = spam, Responce = ham, Kosten = 0.34376999999999996, TP= 38\n",
      "Class = spam, Responce = spam, Kosten = 0.34809, TP= 39\n",
      "Class = spam, Responce = spam, Kosten = 0.35292, TP= 40\n",
      "Class = spam, Responce = spam, Kosten = 0.37041, TP= 41\n",
      "Class = spam, Responce = spam, Kosten = 0.37559999999999993, TP= 42\n",
      "Class = spam, Responce = spam, Kosten = 0.3791999999999999, TP= 43\n",
      "Class = spam, Responce = spam, Kosten = 0.38009999999999994, TP= 44\n",
      "Class = spam, Responce = spam, Kosten = 0.40046999999999994, TP= 45\n",
      "Class = spam, Responce = spam, Kosten = 0.40884, TP= 46\n",
      "Class = spam, Responce = spam, Kosten = 0.41096999999999995, TP= 47\n",
      "Class = spam, Responce = spam, Kosten = 0.41348999999999997, TP= 48\n",
      "Class = spam, Responce = spam, Kosten = 0.42425999999999997, TP= 49\n",
      "Class = spam, Responce = spam, Kosten = 0.43079999999999996, TP= 50\n",
      "Class = spam, Responce = spam, Kosten = 0.43190999999999996, TP= 51\n",
      "Class = spam, Responce = spam, Kosten = 0.43274999999999997, TP= 52\n",
      "Class = spam, Responce = ham, Kosten = 0.43668, TP= 52\n",
      "Class = spam, Responce = spam, Kosten = 0.43922999999999995, TP= 53\n",
      "Class = spam, Responce = spam, Kosten = 0.44060999999999995, TP= 54\n",
      "Class = spam, Responce = spam, Kosten = 0.44153999999999993, TP= 55\n",
      "Class = spam, Responce = spam, Kosten = 0.44501999999999997, TP= 56\n",
      "Class = spam, Responce = spam, Kosten = 0.45122999999999996, TP= 57\n",
      "The accuracy of the model is: 0.95 and cost: 0.45122999999999996 and execution time: 48.41394400596619\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "Ges = len(df_spam_subset)\n",
    "ges_len_input = 0\n",
    "ges_len_responce = 0\n",
    "elapsed_time_ges = 0\n",
    "# Iterieren über die \"Text\"-Spalte und Drucken jedes Eintrags\n",
    "for index,text_entry in enumerate(df_spam_subset['text']):\n",
    "    if 'gpt'in llm:\n",
    "        len_input = num_tokens_from_string(text_entry, llm)\n",
    "        ges_len_input += len_input\n",
    "    else:\n",
    "        len_input = num_tokens_from_string(text_entry, \"gpt-3.5-turbo\")\n",
    "        ges_len_responce = 0\n",
    "    if len_input>4097:\n",
    "        text_entry = text_entry[:-int((1-((4097/len_input)-0.05))*len(text_entry))]\n",
    "\n",
    "    cat = df_spam_subset[\"label\"].iloc[index]\n",
    "    #ausführung Modell + Zeitstoppen\n",
    "    start_time = time.time()\n",
    "    responce = generate_gpt_response(text_entry)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_ges += elapsed_time\n",
    "\n",
    "    if 'gpt'in llm:\n",
    "        len_output_tokens = num_tokens_from_string(responce, llm)\n",
    "        ges_len_responce += len_output_tokens\n",
    "    else:\n",
    "        ges_len_responce = 0\n",
    "    kosten = kostenrechner(ges_len_input, ges_len_responce)\n",
    "    if cat == responce:\n",
    "        TP+=1\n",
    "    print(f\"Class = {cat}, Responce = {responce}, Kosten = {kosten}, TP= {TP}\")\n",
    "    \n",
    "kosten = kostenrechner(ges_len_input, ges_len_responce)\n",
    "Acc = TP/Ges\n",
    "print(f\"The accuracy of the model is: {Acc} and cost: {kosten} and execution time: {elapsed_time_ges}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste zum Speichern der ausgewählten DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Gruppieren nach 'Kategorie' und nehmen von 5 Stichproben für jede Gruppe\n",
    "for name, group in df_spam.groupby('Kategorie'):\n",
    "    dfs.append(group.sample(min(len(group), 5)))\n",
    "\n",
    "# Kombinieren aller gesammelten DataFrames\n",
    "subset_spam_df = pd.concat(dfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
