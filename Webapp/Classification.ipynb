{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation von Spam Mails und E-Maildaten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import streamlit as st\n",
    "import time\n",
    "import replicate\n",
    "import os\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens und Kosten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kostenrechner(anzahl_input,anzahl_output):\n",
    "    if llm == 'gpt-4':\n",
    "        kosten = ((0.03/1000)*anzahl_input)+((0.06/1000)*anzahl_output)\n",
    "    elif llm == 'gpt-3.5-turbo':\n",
    "        kosten = ((0.0015/1000)*anzahl_input)+((0.002/1000)*anzahl_output)\n",
    "    else:        \n",
    "        kosten = elapsed_time_ges*(0.001400)\n",
    "    return kosten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier eigenen Openai und LLama Key hinzufügen\n",
    "open_api = st.secrets['API_TOKEN']['openai_api']\n",
    "openai.api_key = open_api\n",
    "replicate_api = st.secrets['API_TOKEN']['replicate_api_token']\n",
    "os.environ['REPLICATE_API_TOKEN'] = replicate_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm='gpt-3.5-turbo' #gpt-3.5-turbo, gpt-4, replicate/llama70b-v2-chat:e951f18578850b652510200860fc4ea62b3b16fac280f83ff32282f87bbd2e48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = replicate.run('a16z-infra/llama7b-v2-chat:4f0a4744c7295c024a1de15e1a63c880d3da035fa1f49bfd344fe076074c8eea', \n",
    "                           input={\"prompt\": \"You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'. \"+ \"hallo\"+\" Assistant: \",\n",
    "                                  \"temperature\":0.1, \"top_p\":0.9, \"max_length\":4097, \"repetition_penalty\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response\n",
    "full_response = ''\n",
    "for item in response:\n",
    "    full_response += item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have a question about the weather. Can you tell me the current weather conditions for New York City?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### promt generierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt_response(prompt_input):\n",
    "    messages=[{f\"role\": \"system\", \"content\": context}]\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt_input})\n",
    "    if 'gpt' in llm:\n",
    "        response = openai.ChatCompletion.create(model=llm, messages=messages)\n",
    "        full_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        response = replicate.run(llm, \n",
    "                           input={\"prompt\": \"You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'. \"+ context+\"\\n The Mail starts here:\"+ df_spam_subset['text'][0]+\" Assistant: \",\n",
    "                                  \"temperature\":0.1, \"top_p\":0.9, \"max_length\":4097, \"repetition_penalty\":1})\n",
    "        full_response = ''\n",
    "        for item in response:\n",
    "            full_response += item\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(df,  anzahl):\n",
    "    # Liste zum Speichern der ausgewählten DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Gruppieren nach 'Kategorie' und nehmen von 5 Stichproben für jede Gruppe\n",
    "    for name, group in df.groupby('Kategorie'):\n",
    "        dfs.append(group.sample(min(len(group), anzahl)))\n",
    "\n",
    "    # Kombinieren aller gesammelten DataFrames\n",
    "    con_df = pd.concat(dfs)\n",
    "    \n",
    "    return con_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"Ich werde dir jetzt Zeitungsartikel aus Österreich schicken die du Klassifizieren sollst, dabei sind die Kategorien:[Web, Panorama, International, Wirtschaft, Sport, Inland, Etat, Wissenschaft, Kultur]. Antworte jeweils nur mit der zugehörigen Kategorie.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/test_news.csv', delimiter=';', usecols=[0, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = subset(df,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "Ges = len(subset_df)\n",
    "# Iterieren über die \"Text\"-Spalte und Drucken jedes Eintrags\n",
    "for index,text_entry in enumerate(subset_df['Text']):\n",
    "    cat = subset_df[\"Kategorie\"].iloc[index]\n",
    "    responce = generate_gpt_response(text_entry)\n",
    "    print(f\"Class = {cat}, Responce = {responce}\")\n",
    "    if cat == responce:\n",
    "        TP+=1\n",
    "Acc = TP/Ges\n",
    "print(f\"Die Accuracy des Modells beträgt:{Acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=\"I will now send you emails that are either spam or harmless. Please only answer me with “spam” for spam emails or “ham” for harmless emails!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = pd.read_csv('../Data/spam_ham_dataset.csv', sep = \",\")\n",
    "\n",
    "df_spam=df_spam[[\"label\",\"text\"]]\n",
    "\n",
    "# Ändern Sie den Namen der Spalte 'A' in 'X'\n",
    "df_spam.rename(columns={'label': 'Kategorie'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam_subset = subset(df_spam, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class = ham, Responce = ham\n",
      "Class = ham, Responce = ham\n",
      "Class = ham, Responce = ham\n",
      "Class = ham, Responce = spam\n",
      "Class = ham, Responce = ham\n",
      "Class = spam, Responce = spam\n",
      "Class = spam, Responce = spam\n",
      "Class = spam, Responce = spam\n",
      "Class = spam, Responce = spam\n",
      "Class = spam, Responce = spam\n",
      "Die Accuracy des Modells beträgt:0.9 und Kosten: 0.004316 und Ausführungszeit:10.965712785720825\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TP = 0\n",
    "Ges = len(df_spam_subset)\n",
    "ges_len_input = 0\n",
    "ges_len_responce = 0\n",
    "elapsed_time_ges = 0\n",
    "# Iterieren über die \"Text\"-Spalte und Drucken jedes Eintrags\n",
    "for index,text_entry in enumerate(df_spam_subset['text']):\n",
    "    len_input = num_tokens_from_string(text_entry, llm)\n",
    "    ges_len_input += len_input\n",
    "    if len_input>4097:\n",
    "        text_entry = text_entry[:-int((1-((4097/len_input)-0.05))*len(text_entry))]\n",
    "    cat = df_spam_subset[\"Kategorie\"].iloc[index]\n",
    "    #ausführung Modell + Zeitstoppen\n",
    "    start_time = time.time()\n",
    "    responce = generate_gpt_response(text_entry)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_ges += elapsed_time\n",
    "\n",
    "    len_output_tokens = num_tokens_from_string(responce, llm)\n",
    "    ges_len_responce += len_output_tokens\n",
    "    print(f\"Class = {cat}, Responce = {responce}\")\n",
    "    if cat == responce:\n",
    "        TP+=1\n",
    "kosten = kostenrechner(ges_len_input, ges_len_responce)\n",
    "Acc = TP/Ges\n",
    "print(f\"Die Accuracy des Modells beträgt:{Acc} und Kosten: {kosten} und Ausführungszeit:{elapsed_time_ges}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste zum Speichern der ausgewählten DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Gruppieren nach 'Kategorie' und nehmen von 5 Stichproben für jede Gruppe\n",
    "for name, group in df_spam.groupby('Kategorie'):\n",
    "    dfs.append(group.sample(min(len(group), 5)))\n",
    "\n",
    "# Kombinieren aller gesammelten DataFrames\n",
    "subset_spam_df = pd.concat(dfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
